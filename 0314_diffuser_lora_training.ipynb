{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xhelloweb3/colab-code/blob/main/0314_diffuser_lora_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAZq3vFDcFiT"
      },
      "source": [
        "# Dreambooth fine-tuning for Stable Diffusion using d🧨ffusers \n",
        "\n",
        "This notebook shows how to \"teach\" Stable Diffusion a new concept via Dreambooth using 🤗 Hugging Face [🧨 Diffusers library](https://github.com/huggingface/diffusers). \n",
        "\n",
        "![Dreambooth Example](https://dreambooth.github.io/DreamBooth_files/teaser_static.jpg)\n",
        "_By using just 3-5 images you can teach new concepts to Stable Diffusion and personalize the model on your own images_ \n",
        "\n",
        "Differently from Textual Inversion, this approach trains the whole model, which can yield better results to the cost of bigger models.\n",
        "\n",
        "For a general introduction to the Stable Diffusion model please refer to this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbzZ9xe6dWwf"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to share your model with the community, there are a few more steps to follow.|\n",
        "\n",
        "First you have to store your authentication token from the Hugging Face website (sign up here if you haven't already!) then execute the following cell and input your write token:"
      ],
      "metadata": {
        "id": "30jGXTbR7_Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "ONa9T9R38AaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30lu8LWXmg5j",
        "outputId": "e4815e0e-3a71-4763-b02c-07ca64c78380",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/diffusers@main\n",
            "  Cloning https://github.com/huggingface/diffusers (to revision main) to /tmp/pip-req-build-ocf0hhpv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-ocf0hhpv\n",
            "  Resolved https://github.com/huggingface/diffusers to commit d9b8adc4cac287a10d0641533bf6741cd9e5c80a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (3.9.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (6.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from diffusers==0.15.0.dev0) (8.4.0)\n",
            "Collecting huggingface-hub>=0.13.0\n",
            "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->diffusers==0.15.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->diffusers==0.15.0.dev0) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->diffusers==0.15.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->diffusers==0.15.0.dev0) (6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata->diffusers==0.15.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->diffusers==0.15.0.dev0) (1.26.14)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.15.0.dev0-py3-none-any.whl size=743346 sha256=f2a4badd33622815d64db77a179cabafdabd8e8bc910423b6bc14e6aa1d7bde4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-d7pc83rw/wheels/2a/d4/87/10e3ecd71a26f8d517a697b37622bf650ffb3f10a95cc3539e\n",
            "Successfully built diffusers\n",
            "Installing collected packages: huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.15.0.dev0 huggingface-hub-0.13.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Install the required libs\n",
        "!pip install git+https://github.com/huggingface/diffusers@main\n",
        "!pip install -qq accelerate tensorboard transformers ftfy gradio datasets\n",
        "!pip install -qq \"ipywidgets>=7,<8\"\n",
        "!pip install -qq bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll119uOhEUPL",
        "outputId": "53ce9ff9-349d-4461-abea-2f5ff28c13c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.9/dist-packages (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton) (3.22.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton) (3.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from triton) (1.13.1+cu116)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton) (16.0.0rc3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->triton) (4.5.0)\n",
            "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not install requirement xformers==0.0.13.dev0 from https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl because of HTTP error 404 Client Error: Not Found for url: https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl for URL https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\u001b[0m\u001b[31m\n",
            "\u001b[0mCPU times: user 32 ms, sys: 237 ms, total: 269 ms\n",
            "Wall time: 5.67 s\n"
          ]
        }
      ],
      "source": [
        "#@title [Optional] Install xformers for faster and memory efficient training\n",
        "#@markdown Acknowledgement: The xformers wheel are taken from [TheLastBen/fast-stable-diffusion](https://github.com/TheLastBen/fast-stable-diffusion). Thanks a lot for building these wheels!\n",
        "%%time\n",
        "\n",
        "!pip install -U --pre triton\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1_h0kO-VnQog"
      },
      "outputs": [],
      "source": [
        "#@title Import required libraries\n",
        "import argparse\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "from contextlib import nullcontext\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import PIL\n",
        "from accelerate import Accelerator\n",
        "from accelerate.logging import get_logger\n",
        "from accelerate.utils import set_seed\n",
        "from diffusers import AutoencoderKL, DDPMScheduler, PNDMScheduler, StableDiffusionPipeline, UNet2DConditionModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
        "\n",
        "import bitsandbytes as bnb\n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl3r7A_3ASxm"
      },
      "source": [
        "## Settings for teaching your new concept"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If5Jswe526QP"
      },
      "outputs": [],
      "source": [
        "#@markdown `pretrained_model_name_or_path` which Stable Diffusion checkpoint you want to use\n",
        "pretrained_model_name_or_path = \"Linaqruf/anything-v3.0\" #@param [\"stabilityai/stable-diffusion-2\", \"stabilityai/stable-diffusion-2-base\", \"CompVis/stable-diffusion-v1-4\", \"runwayml/stable-diffusion-v1-5\"] {allow-input: true}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gIFaJum5nqeo"
      },
      "outputs": [],
      "source": [
        "#@title Load the Stable Diffusion model\n",
        "# Load models and create wrapper for stable diffusion\n",
        "text_encoder = CLIPTextModel.from_pretrained(\n",
        "    pretrained_model_name_or_path, subfolder=\"text_encoder\"\n",
        ")\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    pretrained_model_name_or_path, subfolder=\"vae\"\n",
        ")\n",
        "unet = UNet2DConditionModel.from_pretrained(\n",
        "    pretrained_model_name_or_path, subfolder=\"unet\"\n",
        ")\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path,\n",
        "    subfolder=\"tokenizer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLznpOjiBvS"
      },
      "source": [
        "#### Load images from local folder or google drive\n",
        "\n",
        "You can also load your own training images from google drive or upload them to colab usingthe files taband then provide the path to the directory containing images. \n",
        "\n",
        "*Make sure that the directory only contains images as the following cells will read all the files from the provided directory.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEmVZkD8O1e7",
        "outputId": "f57ea016-9b47-4fcc-f975-861586adbcf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWaO3v1OPJ2D"
      },
      "source": [
        "### traing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeb3NmiuQDli",
        "outputId": "3f7b3011-f6d1-42a4-c824-eda5e6dc7690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-14 00:50:08--  https://raw.githubusercontent.com/huggingface/diffusers/correct_lora_saving_loading/examples/text_to_image/train_text_to_image_lora.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36627 (36K) [text/plain]\n",
            "Saving to: ‘train_text_to_image_lora.py.1’\n",
            "\n",
            "train_text_to_image 100%[===================>]  35.77K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-14 00:50:08 (147 MB/s) - ‘train_text_to_image_lora.py.1’ saved [36627/36627]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/diffusers/correct_lora_saving_loading/examples/text_to_image/train_text_to_image_lora.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58gJ_rzUQdFQ",
        "outputId": "e0f11bd6-5e9e-48a2-b78e-79253dfd868e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-14 00:19:25.200429: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-14 00:19:26.285445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:19:26.285549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:19:26.285568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
          ]
        }
      ],
      "source": [
        "!accelerate config default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XCVrQkqPQ6z",
        "outputId": "b047c0f6-cae2-4f2d-b1a0-2ca0445df30a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-14 00:22:00.479773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-14 00:22:01.472266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:22:01.472385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:22:01.472411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-03-14 00:22:05.730489: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:22:05.730611: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-14 00:22:05.730634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.9/dist-packages/accelerate/accelerator.py:243: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
            "  warnings.warn(\n",
            "03/14/2023 00:22:08 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "{'thresholding', 'variance_type', 'clip_sample_range', 'sample_max_value', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'mid_block_type', 'projection_class_embeddings_input_dim', 'time_embedding_type', 'class_embed_type', 'conv_in_kernel', 'timestep_post_act', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'conv_out_kernel'} was not found in config. Values will be initialized to default values.\n",
            "03/14/2023 00:22:24 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/ethers___parquet/ethers--azuki-datasets-e39c6017f8b124cd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "100% 1/1 [00:00<00:00, 727.67it/s]\n",
            "03/14/2023 00:22:24 - WARNING - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/ethers___parquet/ethers--azuki-datasets-e39c6017f8b124cd/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ddd5b9917637eb0a.arrow\n",
            "03/14/2023 00:22:25 - INFO - __main__ - ***** Running training *****\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Num examples = 10\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Num Epochs = 1\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "03/14/2023 00:22:25 - INFO - __main__ -   Total optimization steps = 1\n",
            "Steps: 100% 1/1 [00:01<00:00,  1.87s/it, lr=0.0001, step_loss=0.204]Traceback (most recent call last):\n",
            "  File \"/content/train_text_to_image_lora.py\", line 872, in <module>\n",
            "    main()\n",
            "  File \"/content/train_text_to_image_lora.py\", line 825, in main\n",
            "    unet.save_attn_procs(args.output_dir)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/diffusers/loaders.py\", line 273, in save_attn_procs\n",
            "    weights_no_suffix = weights_name.replace(\".bin\", \"\")\n",
            "AttributeError: 'NoneType' object has no attribute 'replace'\n",
            "Steps: 100% 1/1 [00:02<00:00,  2.14s/it, lr=0.0001, step_loss=0.204]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/launch.py\", line 915, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/accelerate/commands/launch.py\", line 578, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', 'train_text_to_image_lora.py', '--pretrained_model_name_or_path=Linaqruf/anything-v3.0', '--dataset_name=ethers/azuki-datasets', '--caption_column=text', '--resolution=512', '--random_flip', '--train_batch_size=1', '--max_train_steps=1', '--checkpointing_steps=1000', '--validation_epochs=100', '--num_validation_images=0', '--output_dir=/content/drive/MyDrive/lora-train-out', '--learning_rate=1e-04', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--seed=42', '--max_train_samples=10']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!accelerate launch --mixed_precision=\"fp16\" train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"Linaqruf/anything-v3.0\" \\\n",
        "  --dataset_name=\"ethers/azuki-datasets\" --caption_column=\"text\" \\\n",
        "  --resolution=512 --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --max_train_steps=1 \\\n",
        "  --checkpointing_steps=1000 \\\n",
        "  --validation_epochs=100 \\\n",
        "  --num_validation_images=0 \\\n",
        "  --output_dir=\"/content/drive/MyDrive/lora-train-out\" \\\n",
        "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
        "  --seed=42 \\\n",
        "  --max_train_samples=10"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit ('3.7.9')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "76721e0cd9246c299eb22246d1f3c601ec1aef6bd84d45d2547549094e7b6fb7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}